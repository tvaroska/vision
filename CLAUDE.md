# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is an FRC (FIRST Robotics Competition) 2025 robot codebase for Team 10413, written in Java using WPILib and the command-based framework. The robot uses a swerve drive platform with CTRE Phoenix 6 hardware (Kraken x60 motors and CANcoders).

## Build System and Commands

This project uses Gradle with the GradleRIO plugin. All commands should be run using the Gradle wrapper (`./gradlew`).

**Common build commands:**
- `./gradlew build` - Build the project
- `./gradlew deploy` - Deploy code to the RoboRIO
- `./gradlew simulateJava` - Run robot simulation with GUI
- `./gradlew test` - Run all tests

**Development commands:**
- `./gradlew tasks` - List all available Gradle tasks

## Hardware Configuration

### Swerve Drivetrain
- **Motors:** CTRE Kraken x60 (TalonFX) motors
- **Encoders:** CTRE CANcoders for absolute position
- **IMU:** Pigeon 2 (CAN ID 20)
- **CAN Bus:** Named "Drivetrain"
- **Module Configuration:** X1 12T (WestCoast Products), 6.39:1 drive ratio, 12.1:1 steer ratio
- **Wheel Radius:** 2 inches
- **Track Width:** 23" x 23"
- **Max Speed:** ~4.99 m/s at 12V (currently limited to 10% via SPEED_MULTIPLIER)

**Module CAN IDs:**
- Front Left: Drive=1, Steer=2, Encoder=24
- Front Right: Drive=19, Steer=18, Encoder=23
- Back Left: Drive=4, Steer=3, Encoder=25
- Back Right: Drive=16, Steer=17, Encoder=26

### Vision System (Dual Camera Setup)
- **Front Camera:** PhotonVision camera facing forward (configurable name: `front_camera`)
  - Position: 0.3m forward from robot center, 0.5m height
  - Orientation: 0° yaw (facing forward)
- **Rear Camera:** PhotonVision camera facing backward (configurable name: `rear_camera`)
  - Position: 0.3m behind robot center, 0.5m height
  - Orientation: 180° yaw (facing backward)
- **AprilTag Detection:** 2025 Reefscape field layout
- **Pose Estimation:** Multi-tag PNP with fallback to lowest ambiguity
- **Vision Fusion:** Kalman filter fuses both cameras with odometry
- **Update Rate:** Both cameras processed every robot loop (~20ms)
- **Max Distance:** 4 meters for vision measurements (configurable)
- **360° Coverage:** Front and rear cameras provide full field awareness

## Architecture

### Package Structure
- `frc.robot` - Main robot classes (Robot, RobotContainer, Constants)
- `frc.robot.subsystems` - Subsystem classes (CommandSwerveDrivetrain, SafetyMonitor, VisionSubsystem, FieldConfiguration)
- `frc.robot.commands` - Command classes (DriveForwardAuto, AutoSelector)
- `frc.robot.generated` - Auto-generated tuner constants (DO NOT manually edit TunerConstants.java - regenerate via Tuner X)
- `src/test/java/frc/robot` - Unit tests for robot code
- `vendordeps/` - Vendor dependencies (Phoenix6, REVLib, PhotonLib)

### Key Classes

**Robot.java**
- Main robot class extending TimedRobot
- Initializes DataLogManager for comprehensive logging
- Manages autonomous command execution

**RobotContainer.java**
- Configures all subsystems and controller bindings
- Uses Constants class for all configuration values
- Xbox controller (port 0) for all controls
- Includes AutoSelector for autonomous mode selection
- SafetyMonitor for robot health tracking

**Constants.java**
- Central location for all robot constants
- Organized into nested classes: OI, Drivetrain, Safety, Auto, Vision
- All magic numbers should be defined here
- Vision constants include camera position, trust levels, and filtering parameters

**CommandSwerveDrivetrain.java**
- Extends Phoenix 6 SwerveDrivetrain with WPILib command support
- Includes SysId characterization routines
- Auto-applies operator perspective based on alliance color
- Simulation support built-in

**TunerConstants.java (generated)**
- Generated by CTRE Tuner X - **DO NOT manually edit**
- Contains all swerve module constants, PID gains, gear ratios, offsets
- Regenerate via Tuner X if hardware changes

**Telemetry.java**
- Publishes swerve state to NetworkTables and SignalLogger
- Mechanism2d visualization for module states
- Field2d pose visualization

**SafetyMonitor.java**
- Monitors battery voltage, current draw, and CAN bus utilization
- Automatic warning/error reporting for critical conditions
- Tracks peak current and lowest voltage
- Publishes comprehensive safety metrics to SmartDashboard
- Configurable thresholds in Constants.Safety

**DriveForwardAuto.java**
- Simple autonomous command to drive forward
- Configurable speed and duration
- Uses FieldCentric drive request

**DriveToAprilTag.java**
- **Generalized vision-based AprilTag alignment command**
- Uses front camera real-time detection (not field layout)
- Robot-centric control based on vision yaw and distance
- **Flexible targeting:**
  - Can target specific tag by ID
  - Can target nearest visible tag (ID = -1)
  - Configurable distance in inches or meters
- **Factory methods for easy use:**
  - `DriveToAprilTag.toTag(drivetrain, vision, tagID)` - Default 20" distance
  - `DriveToAprilTag.toTag(drivetrain, vision, tagID, inches)` - Custom distance
  - `new DriveToAprilTag(drivetrain, vision)` - Nearest tag at 20"
- Uses 3 PID controllers:
  - Forward: Achieve target distance
  - Strafe: Center on tag (zero yaw)
  - Rotation: Face tag directly
- Runs continuously while button held
- **Example:** `DriveToAprilTag.toTag(drivetrain, visionSubsystem, 1, 20)` = Tag 1 at 20 inches

**AutoSelector.java**
- SendableChooser for autonomous mode selection
- Multiple auto options available via SmartDashboard
- Options: Do Nothing, Drive Forward (default/short/long)

**VisionSubsystem.java**
- Dual camera AprilTag detection using PhotonVision
- Front camera: Forward-facing for offensive positioning
- Rear camera: Backward-facing for defensive positioning
- Automatic pose estimation using FieldConfiguration
- Multi-tag fusion for improved accuracy
- Dynamic trust scaling based on distance and number of tags
- Quality filtering (ambiguity, distance checks)
- Independent processing for each camera
- Integrates with drivetrain Kalman filter via `addVisionMeasurement()`
- Per-camera telemetry published to SmartDashboard:
  - "Vision/Front/" - Front camera data
  - "Vision/Rear/" - Rear camera data
  - "Vision/Front Initialized" - Front camera status
  - "Vision/Rear Initialized" - Rear camera status

**FieldConfiguration.java**
- Utility class for managing field layouts
- Supports multiple field modes:
  - `REAL_FIELD` - Official 2025 Reefscape field with all 16 AprilTags
  - `TRAINING_FIELD_1_TAG` - Single AprilTag for basic testing
  - `TRAINING_FIELD_2_TAGS` - Two AprilTags for alignment testing
  - `TRAINING_FIELD_3_TAGS` - Three AprilTags for full pose estimation
- All training tag positions configurable in Constants.Vision
- Utility method `printFieldLayout()` to debug tag positions
- Switch modes in `Constants.Vision.FIELD_MODE` and redeploy

### Control Mappings (Xbox Controller Port 0)

**Driving:**
- Left stick Y: Forward/backward translation
- Left stick X: Left/right translation
- Right stick X: Rotation
- Left bumper: Reset field-centric heading
- A button: Brake mode (locks wheels in X pattern)
- B button: Point wheels toward joystick direction
- **X button (hold): Drive to AprilTag** - Uses front camera vision to automatically drive to AprilTag 1 at 20 inches distance (configurable in RobotContainer.java)

**SysId Characterization:**
- Back + Y: Dynamic forward
- Back + X: Dynamic reverse (Note: conflicts with X button autonomous drive)

## Important Notes

- **Constants Management:** All robot constants are in `Constants.java`. Add new constants there, not scattered in code.
- **Tuner Constants:** The `generated/TunerConstants.java` file is auto-generated by CTRE Tuner X. To modify swerve configuration, use Tuner X and regenerate this file.
- **Logging:** DataLogManager is enabled by default. Logs are saved to the robot and can be analyzed post-match.
- **Safety Monitoring:** SafetyMonitor subsystem runs automatically and reports voltage/current issues. Check SmartDashboard under "Safety/" for metrics.
- **Autonomous:** Use SmartDashboard's "Auto Selector" to choose autonomous modes before enabling.
- **Testing:** Unit tests are in `src/test/java`. Run with `./gradlew test`.
- **AprilTag Alignment (Vision-Based):** The `DriveToAprilTag` command is fully generalized. Change target tag and distance in `RobotContainer.java`:
  - Current binding: `DriveToAprilTag.toTag(drivetrain, visionSubsystem, 1, 20)` (Tag 1 at 20 inches)
  - For different tag: `DriveToAprilTag.toTag(drivetrain, visionSubsystem, 5, 30)` (Tag 5 at 30 inches)
  - For nearest tag: `new DriveToAprilTag(drivetrain, visionSubsystem)` (Nearest at 20 inches)
  - Requires front camera to be active and detecting tags
- The drivetrain uses open-loop voltage control by default for drive motors
- Field-centric heading is automatically set based on alliance color (blue=0°, red=180°)
- All swerve hardware is on a separate CAN bus named "Drivetrain"
- Simulation is enabled by default and runs at 200 Hz (5ms period)

### Vision System Setup (Dual Cameras)

**Field Configuration Modes:**

Switch between field layouts by changing `Constants.Vision.FIELD_MODE`:
- **REAL_FIELD** - Official 2025 Reefscape competition field (16 tags)
- **TRAINING_FIELD_1_TAG** - Single AprilTag for basic vision testing
- **TRAINING_FIELD_2_TAGS** - Two AprilTags for alignment practice
- **TRAINING_FIELD_3_TAGS** - Three AprilTags for full pose estimation testing

Training tag positions are fully configurable in `Constants.Vision`:
- Tag 1: Center position (X=4.0m, Y=3.0m) - Used in all training modes
- Tag 2: Left position (X=4.0m, Y=1.0m) - Used in 2 and 3 tag modes
- Tag 3: Right position (X=4.0m, Y=5.0m) - Used in 3 tag mode only
- Training field: 8m × 6m (smaller than competition field)
- All tags at 1.45m height, facing 180° (toward robot start)

**PhotonVision Configuration:**
1. Install PhotonVision on TWO coprocessors (or one with two camera inputs)
2. Configure both cameras in PhotonVision web interface:
   - Front camera: Name as "front_camera" (or update `Constants.Vision.FRONT_CAMERA_NAME`)
   - Rear camera: Name as "rear_camera" (or update `Constants.Vision.REAR_CAMERA_NAME`)
3. Load appropriate AprilTag layout in PhotonVision (or use robot-side configuration)
4. Enable multi-tag detection for best accuracy on both cameras

**Camera Calibration (Do for BOTH cameras):**
1. Calibrate each camera independently using PhotonVision calibration tool
2. Measure each camera's position relative to robot center:
   - **Front camera:** Currently 0.3m forward, centered laterally, 0.5m height
   - **Rear camera:** Currently 0.3m backward, centered laterally, 0.5m height
3. Update `Constants.Vision` offset values for each camera (X, Y, Z in meters)
4. Measure camera tilt angles and update ROLL/PITCH/YAW for each camera
5. **Important:** Rear camera YAW must be 180° (facing backward)

**Tuning Vision Trust:**
- Adjust `VISION_MEASUREMENT_STD_DEVS` for base trust level (lower = more trust)
- Adjust `DISTANCE_WEIGHT` for distance-based scaling (higher = less trust at distance)
- Adjust `MAX_VISION_DISTANCE` to reject far-away detections
- Adjust `MAX_AMBIGUITY` to reject uncertain single-tag detections (0.2-0.4 recommended)
- **Note:** Trust parameters apply to BOTH cameras

**Monitoring (Per-Camera Telemetry):**
Check SmartDashboard for real-time data:

**Front Camera ("Vision/Front/"):**
  - "Has Targets" - Whether front camera sees AprilTags
  - "Target Count" - Number of tags visible to front camera
  - "Using Measurement" - Whether front vision update was accepted
  - "Connected" - Front camera connection status
  - "Estimated X/Y/Rotation" - Front camera pose estimate

**Rear Camera ("Vision/Rear/"):**
  - "Has Targets" - Whether rear camera sees AprilTags
  - "Target Count" - Number of tags visible to rear camera
  - "Using Measurement" - Whether rear vision update was accepted
  - "Connected" - Rear camera connection status
  - "Estimated X/Y/Rotation" - Rear camera pose estimate

**Overall ("Vision/"):**
  - "Front Initialized" - Front camera system status
  - "Rear Initialized" - Rear camera system status

**Benefits of Dual Cameras:**
- 360° field coverage - always see AprilTags regardless of robot orientation
- Improved accuracy from multiple perspectives
- Redundancy - system works even if one camera fails
- Better performance in corners and along walls
